{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:45.941153800Z",
     "start_time": "2023-12-26T09:58:45.863301700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def calculate_and_update_cost(input_prompt: str, output_response: str):\n",
    "    cost_per_1000_characters = 0.0001\n",
    "    total_char_usage = len(input_prompt) + len(output_response)\n",
    "    total_cost = total_char_usage * cost_per_1000_characters / 1000\n",
    "\n",
    "    try:\n",
    "        with open(\"token_usage.json\", 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except (json.JSONDecodeError, FileNotFoundError):\n",
    "        data = {}\n",
    "\n",
    "    data['total_char_usage'] = data.get('total_char_usage', 0) + total_char_usage\n",
    "    data['total_cost'] = data.get('total_cost', 0) + total_cost\n",
    "\n",
    "    with open(\"token_usage.json\", 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "    return total_cost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:46.047958300Z",
     "start_time": "2023-12-26T09:58:45.875171600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"What is the total Google/Apple/Samsung traffic for X partner for A B Week/Month?\", 'traffic_metrics'),\n",
    "    (\"Which country has the highest Google weekly traffic?\", 'traffic_metrics'),\n",
    "    (\"What is the Google Share of Traffic (SoT) for US Partners?\", 'traffic_metrics'),\n",
    "    (\"What is the Pixel 8 traffic for Verizon for the last quarter?\", 'traffic_metrics'),\n",
    "    (\"Which model had the highest Week-over-Week (WoW) increase in traffic for Bestbuy?\", 'traffic_metrics'),\n",
    "    (\"What is the total Google weekly traffic for each region?\", 'traffic_metrics'),\n",
    "    (\"Which region has the highest share of Google Traffic?\", 'traffic_metrics'),\n",
    "    (\"Can you identify regions with a significant increase/decrease in Google Traffic compared to the previous week?\", 'traffic_metrics'),\n",
    "    (\"Which countries contribute the most to overall online traffic?\", 'traffic_metrics'),\n",
    "    (\"What is the total Google weekly traffic for each country?\", 'traffic_metrics'),\n",
    "    (\"Which country has the highest Google weekly traffic across countries?\", 'traffic_metrics'),\n",
    "    (\"What is the Share of Traffic (SoT) of Google of traffic in each country?\", 'traffic_metrics'),\n",
    "    (\"Which country has the highest/lowest Google SoT?\", 'traffic_metrics'),\n",
    "    (\"Are there countries where Google Traffic has decreased/increased recently?\", 'traffic_metrics'),\n",
    "    (\"What is the total Partner traffic?\", 'traffic_metrics'),\n",
    "    (\"What is the total Google/Apple/Samsung traffic for X partner for AB Week/Month?\", 'traffic_metrics'),\n",
    "    (\"Which partner has the highest/lowest traffic?\", 'traffic_metrics'),\n",
    "    (\"Which partner has the highest/lowest Google Product Detail Page (PDP) traffic?\", 'traffic_metrics'),\n",
    "    (\"What is the total Google traffic?\", 'traffic_metrics'),\n",
    "    (\"Which partner has the highest/lowest Google SoT?\", 'traffic_metrics'),\n",
    "    (\"What is Google SoT for X partner?\", 'traffic_metrics'),\n",
    "    (\"Which partner has increased/dipped in SoT/visits for Google?\", 'traffic_metrics'),\n",
    "    (\"Comparison of absolute traffic between 2/3 brands?\", 'traffic_metrics'),\n",
    "    (\"Comparison of SOT traffic between 2/3 brands?\", 'traffic_metrics'),\n",
    "    (\"Which Brand has the highest absolute traffic/SoT between X Countries/Y Partners?\", 'traffic_metrics'),\n",
    "    (\"What is the total Model Traffic for Y Region/Z Country/A Retailer?\", 'traffic_metrics'),\n",
    "    (\"Which model has the highest traffic for Y Region/Z Country/A Retailer?\", 'traffic_metrics'),\n",
    "    ('What is the total Metrics for Retailer?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product?', 'sales_data'),\n",
    "    ('What is the total Metrics Pxl Product?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product for X LocationHolder?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product for X SubLocationHolder?', 'sales_data'),\n",
    "    ('Which retailer had higher sales for Pixel 8 Pro?', 'sales_data'),\n",
    "    ('Which n stores have the highest/lowest sales? (by default, n resorts to 10)', 'sales_data'),\n",
    "    ('Which stores have zero sales?', 'sales_data' ),\n",
    "    ('Which store has achieved the target?', 'sales_data'),\n",
    "    ('Which stores have not achieved the target?', 'sales_data'),\n",
    "    (' Which stores have not achieved their target in the past 4 weeks?', 'sales_data'),\n",
    "    ('What is the metric for the XYZ store?', 'sales_data'),\n",
    "    ('What are the total covered stores for AT&T?', 'sales_data'),\n",
    "    ('How many TSMs/Markets/ do we have for AT&T?', 'sales_data'),\n",
    "    ('What was the Total RETAILER Account Level Sales?', 'sales_data'),\n",
    "    ('What was the total Target for RETAILER (Online/Offline)?', 'sales_data'),\n",
    "    ('What was the total Achievement % for PxlProduct for RETAILER?', 'sales_data'),\n",
    "    ('What is the Run Rate (Current/Required) for Retailer?', 'sales_data'),\n",
    "    ('What is the Run Rate Per Door (Current/Required) for Retailer?', 'sales_data'),\n",
    "    ('What was the Total PxlProduct Sales for Timeline?', 'sales_data'),\n",
    "    ('What was the Total RETAILER Account Level Sales?', 'sales_data'),\n",
    "    ('What were the Sales for specific Pxl Product x ?', 'sales_data'),\n",
    "    ('What was the Total Attainment % for PxlProduct for RETAILER?', 'sales_data'),\n",
    "    ('What was the Delta between Forecasted and Actuals % for All Pixel Products?', 'sales_data'),\n",
    "    ('What was the Delta between Forecasted and Actuals % for 1 specific Pixel Product?', 'sales_data'),\n",
    "    ('What is the total Google/Apple/Samsung visits for X partner for A B Week/Month?', 'traffic_metrics'),\n",
    "    ('Which country has the highest Google weekly visits?', 'traffic_metrics'),\n",
    "    ('What is the Google Share of Visits (SoV) for US Partners?', 'traffic_metrics'),\n",
    "    ('What is the Pixel 8 visits for Verizon for the last quarter?', 'traffic_metric'),\n",
    "    ('Which model had the highest Week-over-Week (WoW) increase in visits for Bestbuy?', 'traffic_metrics'),\n",
    "    ('What is the total Google weekly visits for each region?', 'traffic_metrics'),\n",
    "    ('Which region has the highest share of Google Visits?', 'traffic_metrics'),\n",
    "    ('Can you identify regions with a significant increase/decrease in Google Visits compared to the previous week?', 'traffic_metrics'),\n",
    "    ('Which countries contribute the most to overall online visits?', 'traffic_metrics'),\n",
    "    ('What is the total Google weekly visits for each country?', 'traffic_metrics'),\n",
    "    ('Which country has the highest Google weekly visits across countries?', 'traffic_metrics'),\n",
    "    ('What is the Share of Visits (SoV) of Google of visits in each country?', 'traffic_metrics'),\n",
    "    ('Which country has the highest/lowest Google SoV?', 'traffic_metrics'),\n",
    "    ('Are there countries where Google Visits has decreased/increased recently?', 'traffic_metrics'),\n",
    "    ('What is the total Partner visits?', 'traffic_metrics'),\n",
    "    ('What is the total Google/Apple/Samsung visits for X partner for AB Week/Month?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest visits?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest Google Product Detail Page (PDP) visits?', 'traffic_metrics'),\n",
    "    ('What is the total Google visits?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest Google SoV?', 'traffic_metrics'),\n",
    "    ('What is Google SoV for X partner?', 'traffic_metrics'),\n",
    "    ('Which partner has increased/dipped in SoV/visits for Google?', 'traffic_metrics'),\n",
    "    ('Comparison of absolute visits between 2/3 brands?', 'traffic_metrics'),\n",
    "    ('Comparison of SOV visits between 2/3 brands?', 'traffic_metrics'),\n",
    "    ('Which Brand has the highest absolute visits/SoV between X Countries/Y Partners?', 'traffic_metrics'),\n",
    "    ('What is the total Model Visits for Y Region/Z Country/A Retailer?', 'traffic_metrics'),\n",
    "    ('Which model has the highest visits for Y Region/Z Country/A Retailer?', 'traffic_metrics'),\n",
    "    ('What is the average Google/Apple/Samsung engagement for X partner for A B Week/Month?', 'traffic_metrics'),\n",
    "    ('Which country has the highest average Google weekly engagement?', 'traffic_metrics'),\n",
    "    ('What is the Google Share of Engagement (SoE) for US Partners?', 'traffic_metrics'),\n",
    "    ('What is the Pixel 8 average engagement for Verizon for the last quarter?', 'traffic_metrics'),\n",
    "    ('Which model had the highest average Week-over-Week (WoW) increase in engagement for Bestbuy?', 'traffic_metrics'),\n",
    "    ('What is the average Google weekly engagement for each region?', 'traffic_metrics'),\n",
    "    ('Which region has the highest average share of Google Engagement?', 'traffic_metrics'),\n",
    "    ('Can you identify regions with a significant increase/decrease in Google Engagement compared to the previous week?', 'traffic_metrics'),\n",
    "    ('Which countries contribute the most to overall average online engagement?', 'traffic_metrics'),\n",
    "    ('What is the average total Google weekly engagement for each country?', 'traffic_metrics'),\n",
    "    ('Which country has the highest average Google weekly engagement across countries?', 'traffic_metrics'),\n",
    "    ('What is the average Share of Engagement (SoE) of Google engagement in each country?', 'traffic_metrics'),\n",
    "    ('Which country has the highest/lowest average Google SoE?', 'traffic_metrics'),\n",
    "    ('Are there countries where average Google Engagement has decreased/increased recently?', 'traffic_metrics'),\n",
    "    ('What is the average total Partner engagement?', 'traffic_metrics'),\n",
    "    ('What is the average Google/Apple/Samsung engagement for X partner for AB Week/Month?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest average engagement?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest average Google Product Detail Page (PDP) engagement?', 'traffic_metrics'),\n",
    "    ('What is the average total Google engagement?', 'traffic_metrics'),\n",
    "    ('Which partner has the highest/lowest average Google SoE?', 'traffic_metrics'),\n",
    "    ('What is Google SoE for X partner?', 'traffic_metrics'),\n",
    "    ('Which partner has increased/dipped in SoE/engagement for Google?', 'traffic_metrics'),\n",
    "    ('Comparison of average engagement between 2/3 brands?', 'traffic_metrics'),\n",
    "    ('Determine the delta in visits for Pixel 8 in the United States between November and October.', 'traffic_metrics'),\n",
    "    ('Determine the delta in visits for Samsung Galaxy S21 in the UK between September and October.', 'traffic_metrics'),\n",
    "    ('Determine the delta in visits for Oppo Reno 8 in the United States between November and October.', 'traffic_metrics'),\n",
    "    ('Comparison of SOE engagement between 2/3 brands?', 'traffic_metrics'),\n",
    "    ('Which Brand has the highest average engagement/SoE between X Countries/Y Partners?', 'traffic_metrics'),\n",
    "    ('What is the average total Model Engagement for Y Region/Z Country/A Retailer?', 'traffic_metrics'),\n",
    "    ('Which model has the highest average engagement for Y Region/Z Country/A Retailer?', 'traffic_metrics'),\n",
    "    ('What is the total Metrics for Retailer for Engagement?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product for Engagement?', 'sales_data'),\n",
    "    ('What is the total Metrics Pxl Product for Engagement?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product for X LocationHolder for Engagement?', 'sales_data'),\n",
    "    ('What is the total Metrics for Retailer for Pxl Product for X SubLocationHolder for Engagement?', 'sales_data'),\n",
    "    ('Which retailer had higher sales for Pixel 8 Pro for Engagement?', 'sales_data'),\n",
    "    ('Which n stores have the highest/lowest sales for Engagement? (by default, n resorts to 10)', 'sales_data'),\n",
    "    ('Which stores have zero sales for Engagement?', 'sales_data'),\n",
    "    ('Which store has achieved the target for Engagement?', 'sales_data'),\n",
    "    ('Which stores have not achieved the target for Engagement?', 'sales_data'),\n",
    "    ('Which stores have not achieved their target in the past 4 weeks for Engagement?', 'sales_data'),\n",
    "    ('What is the metric for the XYZ store for Engagement?', 'sales_data'),\n",
    "    ('What are the total covered stores for AT&T for Engagement?', 'sales_data'),\n",
    "    ('How many TSMs/Markets/ do we have for AT&T for Engagement?', 'sales_data'),\n",
    "    ('What was the Total RETAILER Account Level Sales for Engagement?', 'sales_data'),\n",
    "    ('What was the total Target for RETAILER (Online/Offline) for Engagement?', 'sales_data'),\n",
    "    ('What was the total Achievement % for PxlProduct for RETAILER for Engagement?', 'sales_data'),\n",
    "    ('What is the Run Rate (Current/Required) for Retailer for Engagement?', 'sales_data'),\n",
    "    ('What is the Run Rate Per Door (Current/Required) for Retailer for Engagement?', 'sales_data'),\n",
    "    ('What was the Total PxlProduct Sales for Timeline for Engagement?', 'sales_data'),\n",
    "    ('What was the Total RETAILER Account Level Sales for Engagement?', 'sales_data'),\n",
    "    ('What were the Sales for specific Pxl Product x for Engagement?', 'sales_data'),\n",
    "    ('What was the Total Attainment % for PxlProduct for RETAILER for Engagement?', 'sales_data'),\n",
    "    ('What was the Delta between Forecasted and Actuals % for All Pixel Products for Engagement?', 'sales_data'),\n",
    "    ('What was the Delta between Forecasted and Actuals % for 1 specific Pixel Product for Engagement?', 'sales_data'),\n",
    "    ('What was the total Target for BestBuy?', 'sales_data'),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:46.076086800Z",
     "start_time": "2023-12-26T09:58:45.896234600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier saved successfully.\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     sales_data       1.00      0.86      0.92         7\n",
      "traffic_metrics       0.88      1.00      0.93         7\n",
      "\n",
      "       accuracy                           0.93        14\n",
      "      macro avg       0.94      0.93      0.93        14\n",
      "   weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "X = [preprocess_text(text) for text, _ in data]\n",
    "y = [intent for _, intent in data]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.1, random_state=42)\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "with open('kneighbors_classifier.pkl', 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n",
    "print(\"Classifier saved successfully.\")\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:46.113327Z",
     "start_time": "2023-12-26T09:58:45.908379300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def classify_intent(text):\n",
    "    with open('kneighbors_classifier.pkl', 'rb') as model_file:\n",
    "        loaded_classifier = pickle.load(model_file)\n",
    "    text = preprocess_text(text)\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    intent = loaded_classifier.predict(text_vectorized)[0]\n",
    "    return intent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:46.114327Z",
     "start_time": "2023-12-26T09:58:45.968105200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_data\n",
      "sales_data\n",
      "traffic_metrics\n",
      "traffic_metrics\n",
      "sales_data\n",
      "sales_data\n",
      "traffic_metrics\n",
      "traffic_metrics\n"
     ]
    }
   ],
   "source": [
    "print(classify_intent(\"What were the quarterly Sales for Samsung Galaxy S21?\"))\n",
    "print(classify_intent(\"What was the total Target for BestBuy?\"))\n",
    "print(classify_intent(\"What was the total traffic for AT&T for Apple?\"))\n",
    "print(classify_intent(\"What is Google's total SoT for T-Mobile?\"))\n",
    "print(classify_intent('What are the total covered stores for Verizon?'))\n",
    "print(classify_intent('What is the highest quarterly sales and target?'))\n",
    "print(classify_intent(\"Which partner has the highest visits in the EMEA region?\"))\n",
    "print(classify_intent(\"Which Brand is the most visited among all?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T09:58:46.114327Z",
     "start_time": "2023-12-26T09:58:45.976667900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, text, Table\n",
    "from langchain.llms import VertexAI\n",
    "import dotenv\n",
    "import time\n",
    "import json\n",
    "from datetime import date\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "class CustomAgent:\n",
    "    def __init__(self, database_url: str, llm, verbose: bool = True):\n",
    "        with open('kneighbors_classifier.pkl', 'rb') as model_file:\n",
    "            self.loaded_classifier = pickle.load(model_file)\n",
    "        self.database_url = database_url\n",
    "        self.engine = create_engine(database_url)\n",
    "        self.metadata = MetaData()\n",
    "        self.llm = llm\n",
    "        self.table = None\n",
    "        self.prompt = None\n",
    "        self.schema = None\n",
    "        self.instructions = {\n",
    "            'traffic_metrics': {\n",
    "                'date_of_metrics': f\"(in ISO format, for any time period, mention a range of dates in ISO format if date is mentioned otherwise Null. If you need to know the current date in order to determine the range of dates, current date is {date.today()}),\",\n",
    "                'partner_region': \"(Regions like EMEA, APAC, etc.),\",\n",
    "                'partner_country': \"(in locale code format only, example - US, JP, AU, UK),\",\n",
    "                'partner': \"(example - AT&T, KDDI, Online Docomo, Amazon, Flipkart, Saturn DE. These are vendors. Set it to Null when no partner is mentioned or detected partner is Apple, Google, Samsung, Xiaomi, etc since THESE ARE BRANDS AND NOT PARTNERS),\",\n",
    "                'Brand': \"(Example - Apple, Google, Samsung, Oppo, Xiaomi, Android etc.), \",\n",
    "                'visits': \",\",\n",
    "                'model': \"(actual full official model names, example - 'Google Pixel 7 Pro', 'Apple iPhone 14', 'Samsung S21 Ultra'. If multiple Models exist, add a list a models),\"\n",
    "            },\n",
    "            \"sales_data\": {\n",
    "                'Week': \"(in integers(example 41),\",\n",
    "                'Year': \"(only Year in YYYY form)\",\n",
    "                'Partner': \"(example - AT&T, KDDI, Online Docomo. These are vendors. Partners cannot be Apple or Google.),\",\n",
    "                'Region Type': \",\",\n",
    "                'Region Breakdown': \",\",\n",
    "                'Product Model': \",\",\n",
    "                'Current Week Sales': \",\",\n",
    "                'Quarterly Target': \",\",\n",
    "                'QTD Sales': \",\",\n",
    "                'Current RR': \",\",\n",
    "                'Amended RR': \",\",\n",
    "                'Quarterly %': \",\"\n",
    "            }\n",
    "        }\n",
    "        self.tokens = 0\n",
    "        self.cost = 0\n",
    "        self.verbose = verbose\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def set_prompt(self, prompt):\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def get_table_schema_mysql(self):\n",
    "        table = Table(self.table, self.metadata, autoload_with=self.engine)\n",
    "        if table.columns:\n",
    "            cols = [column.name for column in table.columns]\n",
    "            return cols\n",
    "        else:\n",
    "            print(f\"Table '{self.table}' not found.\")\n",
    "            return None\n",
    "\n",
    "    def get_all_contents(self):\n",
    "        prompt = f\"Extract {' '.join([str(header + self.instructions[self.table][header]) for header in self.schema])} from the following prompt: {self.prompt}. Also extract the of the user 'intent' behind the prompt(example - Total, Average, Highest sales', Lowest, Minimum , Maximum, SoT, WoW, delta(difference) etc. DESCRIBE THE INTENT VERBOSELY and provide context). Also find the TYPE OF OUTPUT expected (Example - Single Value or List of values or a DataFrame). Return the output in JSON format and if any data is not mentioned, leave the parameter empty.\"\n",
    "\n",
    "        response = self.llm.invoke(prompt)\n",
    "        tokens, cost = self.calculate_and_update_cost(prompt, response)\n",
    "        self.tokens += tokens\n",
    "        self.cost += cost\n",
    "\n",
    "        return response\n",
    "\n",
    "    def generate_sql_query(self):\n",
    "        schema = self.get_table_schema_mysql()\n",
    "        self.schema = schema\n",
    "        print(f\"Inferring contents from the prompt with respect to the {self.table}...\" if self.verbose else '')\n",
    "        contents = self.get_all_contents()\n",
    "        print(f\"Inferred Contents: {contents}\" if self.verbose else '')\n",
    "        if schema and contents:\n",
    "            prompt = f\"write a MySQL query for the following prompt: {self.prompt}.Here are the values of parameters for the extracted contents of the prompts - {str(contents)} for table - {self.table} for column names - {schema}. The date is present in the database in an ISO format as a string and not a datetime object. Give me the query in a string\"\n",
    "            response = self.llm.invoke(prompt)\n",
    "\n",
    "            (tokens, cost) = self.calculate_and_update_cost(prompt, response)\n",
    "            self.tokens += tokens\n",
    "            self.cost += cost\n",
    "\n",
    "            return str(response).strip('```')[7:].strip(\"\\n\")\n",
    "        print(\"problem with content or schema detection\")\n",
    "        return None\n",
    "\n",
    "    def run(self, user_input_prompt):\n",
    "        start = time.perf_counter()\n",
    "        self.set_prompt(user_input_prompt)\n",
    "\n",
    "        print(\"Analysing Prompt and Identifying which table to query in the database...\" if self.verbose else '')\n",
    "        self.table = self.classify_intent(user_input_prompt)\n",
    "        print(f\"Identified Table: {self.table}\" if self.verbose else '')\n",
    "\n",
    "        print(\"Generating SQL Query...\" if self.verbose else '')\n",
    "        sql_query = self.generate_sql_query()\n",
    "\n",
    "        print(f\"Generated SQL Query: \\n{sql_query}\")\n",
    "\n",
    "        print(\"Executing SQL Query in the database...\" if self.verbose else '')\n",
    "\n",
    "        if sql_query:\n",
    "            result_df = pd.read_sql_query(sql_query, self.engine)\n",
    "            result_json = result_df.to_json(orient='records')\n",
    "            end = time.perf_counter()\n",
    "            print(f\"Time taken for obtaining results: {(end - start)}s\")\n",
    "            return result_json\n",
    "        else:\n",
    "            end = time.perf_counter()\n",
    "            print(f\"Time taken for obtaining results: {(end - start)}s\")\n",
    "            return \"Unable to generate SQL query.\"\n",
    "\n",
    "    def get_session_usage(self):\n",
    "        print(f\"Usage for the session: \\nTokens: {self.tokens}\\nCost: {self.cost}\")\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in self.stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def classify_intent(self, text):\n",
    "        text = self.preprocess_text(text)\n",
    "        text_vectorized = vectorizer.transform([text])\n",
    "        intent = self.loaded_classifier.predict(text_vectorized)[0]\n",
    "        return intent\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_and_update_cost(input_prompt: str, output_response: str):\n",
    "        cost_per_1000_characters = 0.0001\n",
    "        total_char_usage = len(input_prompt) + len(output_response)\n",
    "        total_cost = total_char_usage * cost_per_1000_characters / 1000\n",
    "\n",
    "        try:\n",
    "            with open(\"token_usage.json\", 'r') as file:\n",
    "                data = json.load(file)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            data = {}\n",
    "\n",
    "        data['total_char_usage'] = data.get('total_char_usage', 0) + total_char_usage\n",
    "        data['total_cost'] = data.get('total_cost', 0) + total_cost\n",
    "\n",
    "        with open(\"token_usage.json\", 'w') as file:\n",
    "            json.dump(data, file, indent=2)\n",
    "\n",
    "        return total_char_usage, total_cost\n",
    "\n",
    "    def insights(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T10:48:31.465613600Z",
     "start_time": "2023-12-26T10:48:31.435399900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "db_url = \"mysql+pymysql://root:root_password@35.239.9.249:3306/gen_ai_test\"\n",
    "agent = CustomAgent(\n",
    "    database_url=db_url,\n",
    "    llm=VertexAI(model='gemini-pro')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T10:48:34.500551300Z",
     "start_time": "2023-12-26T10:48:31.601899200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing Prompt and Identifying which table to query in the database...\n",
      "Identified Table: traffic_metrics\n",
      "Generating SQL Query...\n",
      "Inferring contents from the prompt with respect to the traffic_metrics...\n",
      "Inferred Contents:  ```json\n",
      "{\n",
      "  \"date_of_metrics\": \"2023-11-01/2023-11-30\",\n",
      "  \"partner_region\": null,\n",
      "  \"partner_country\": null,\n",
      "  \"partner\": null,\n",
      "  \"brand\": \"Google\",\n",
      "  \"visits\": null,\n",
      "  \"model\": [\"Google Pixel 7 Pro\"],\n",
      "  \"intent\": \"Total traffic of a specific model in a specific time period\",\n",
      "  \"output_type\": \"Single Value\"\n",
      "}\n",
      "```\n",
      "Generated SQL Query: \n",
      "SELECT SUM(visits) AS total_visits\n",
      "FROM traffic_metrics\n",
      "WHERE Brand = 'Google'\n",
      "  AND model = 'Google Pixel 7 Pro'\n",
      "  AND date_of_metrics BETWEEN '2023-11-01' AND '2023-11-30';\n",
      "Executing SQL Query in the database...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (2006, \"MySQL server has gone away (ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\")\n[SQL: SELECT SUM(visits) AS total_visits\nFROM traffic_metrics\nWHERE Brand = 'Google'\n  AND model = 'Google Pixel 7 Pro'\n  AND date_of_metrics BETWEEN '2023-11-01' AND '2023-11-30';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionResetError\u001B[0m                      Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:803\u001B[0m, in \u001B[0;36mConnection._write_bytes\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 803\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msendall\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mConnectionResetError\u001B[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[1;32m-> 1969\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_has_events:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001B[0m, in \u001B[0;36mDefaultDialect.do_execute\u001B[1;34m(self, cursor, statement, parameters, context)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 922\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\cursors.py:153\u001B[0m, in \u001B[0;36mCursor.execute\u001B[1;34m(self, query, args)\u001B[0m\n\u001B[0;32m    151\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmogrify(query, args)\n\u001B[1;32m--> 153\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_executed \u001B[38;5;241m=\u001B[39m query\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\cursors.py:322\u001B[0m, in \u001B[0;36mCursor._query\u001B[1;34m(self, q)\u001B[0m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clear_result()\n\u001B[1;32m--> 322\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_get_result()\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:557\u001B[0m, in \u001B[0;36mConnection.query\u001B[1;34m(self, sql, unbuffered)\u001B[0m\n\u001B[0;32m    556\u001B[0m     sql \u001B[38;5;241m=\u001B[39m sql\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msurrogateescape\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 557\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCOMMAND\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOM_QUERY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msql\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_affected_rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_query_result(unbuffered\u001B[38;5;241m=\u001B[39munbuffered)\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:861\u001B[0m, in \u001B[0;36mConnection._execute_command\u001B[1;34m(self, command, sql)\u001B[0m\n\u001B[0;32m    860\u001B[0m packet \u001B[38;5;241m=\u001B[39m prelude \u001B[38;5;241m+\u001B[39m sql[: packet_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 861\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_write_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpacket\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DEBUG:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:806\u001B[0m, in \u001B[0;36mConnection._write_bytes\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    805\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_force_close()\n\u001B[1;32m--> 806\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m err\u001B[38;5;241m.\u001B[39mOperationalError(\n\u001B[0;32m    807\u001B[0m     CR\u001B[38;5;241m.\u001B[39mCR_SERVER_GONE_ERROR, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMySQL server has gone away (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    808\u001B[0m )\n",
      "\u001B[1;31mOperationalError\u001B[0m: (2006, \"MySQL server has gone away (ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhat is the traffic of google pixel 7 in November 2023?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# agent.run(\"what were the sales for Pixel 7 Pro in 2023\")\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[54], line 107\u001B[0m, in \u001B[0;36mCustomAgent.run\u001B[1;34m(self, user_input_prompt)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting SQL Query in the database...\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sql_query:\n\u001B[1;32m--> 107\u001B[0m     result_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m     result_json \u001B[38;5;241m=\u001B[39m result_df\u001B[38;5;241m.\u001B[39mto_json(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    109\u001B[0m     end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:486\u001B[0m, in \u001B[0;36mread_sql_query\u001B[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m dtype_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pandasSQL_builder(con) \u001B[38;5;28;01mas\u001B[39;00m pandas_sql:\n\u001B[1;32m--> 486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1776\u001B[0m, in \u001B[0;36mSQLDatabase.read_query\u001B[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m   1719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_query\u001B[39m(\n\u001B[0;32m   1720\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1721\u001B[0m     sql: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1728\u001B[0m     dtype_backend: DtypeBackend \u001B[38;5;241m|\u001B[39m Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1729\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Iterator[DataFrame]:\n\u001B[0;32m   1730\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1731\u001B[0m \u001B[38;5;124;03m    Read SQL query into a DataFrame.\u001B[39;00m\n\u001B[0;32m   1732\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1774\u001B[0m \n\u001B[0;32m   1775\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1776\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1777\u001B[0m     columns \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[0;32m   1779\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1599\u001B[0m, in \u001B[0;36mSQLDatabase.execute\u001B[1;34m(self, sql, params)\u001B[0m\n\u001B[0;32m   1597\u001B[0m args \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;28;01mif\u001B[39;00m params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m [params]\n\u001B[0;32m   1598\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sql, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m-> 1599\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexec_driver_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1600\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcon\u001B[38;5;241m.\u001B[39mexecute(sql, \u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1778\u001B[0m, in \u001B[0;36mConnection.exec_driver_sql\u001B[1;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[0;32m   1773\u001B[0m execution_options \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execution_options\u001B[38;5;241m.\u001B[39mmerge_with(\n\u001B[0;32m   1774\u001B[0m     execution_options\n\u001B[0;32m   1775\u001B[0m )\n\u001B[0;32m   1777\u001B[0m dialect \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdialect\n\u001B[1;32m-> 1778\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1779\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecution_ctx_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_statement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1786\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1788\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1848\u001B[0m, in \u001B[0;36mConnection._execute_context\u001B[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001B[0m\n\u001B[0;32m   1843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exec_insertmany_context(\n\u001B[0;32m   1844\u001B[0m         dialect,\n\u001B[0;32m   1845\u001B[0m         context,\n\u001B[0;32m   1846\u001B[0m     )\n\u001B[0;32m   1847\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1848\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_single_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1849\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\n\u001B[0;32m   1850\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1988\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1985\u001B[0m     result \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39m_setup_result_proxy()\n\u001B[0;32m   1987\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1988\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_dbapi_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1989\u001B[0m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1990\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1992\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2343\u001B[0m, in \u001B[0;36mConnection._handle_dbapi_exception\u001B[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001B[0m\n\u001B[0;32m   2341\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m should_wrap:\n\u001B[0;32m   2342\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m sqlalchemy_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2343\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m sqlalchemy_exception\u001B[38;5;241m.\u001B[39mwith_traceback(exc_info[\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   2344\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2345\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m exc_info[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1967\u001B[0m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[1;32m-> 1969\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_has_events:\n\u001B[0;32m   1974\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39mafter_cursor_execute(\n\u001B[0;32m   1975\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1976\u001B[0m         cursor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1980\u001B[0m         context\u001B[38;5;241m.\u001B[39mexecutemany,\n\u001B[0;32m   1981\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001B[0m, in \u001B[0;36mDefaultDialect.do_execute\u001B[1;34m(self, cursor, statement, parameters, context)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 922\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\cursors.py:153\u001B[0m, in \u001B[0;36mCursor.execute\u001B[1;34m(self, query, args)\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    151\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmogrify(query, args)\n\u001B[1;32m--> 153\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_executed \u001B[38;5;241m=\u001B[39m query\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\cursors.py:322\u001B[0m, in \u001B[0;36mCursor._query\u001B[1;34m(self, q)\u001B[0m\n\u001B[0;32m    320\u001B[0m conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_db()\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clear_result()\n\u001B[1;32m--> 322\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_get_result()\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrowcount\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:557\u001B[0m, in \u001B[0;36mConnection.query\u001B[1;34m(self, sql, unbuffered)\u001B[0m\n\u001B[0;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sql, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    556\u001B[0m     sql \u001B[38;5;241m=\u001B[39m sql\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msurrogateescape\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 557\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCOMMAND\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOM_QUERY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msql\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_affected_rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_query_result(unbuffered\u001B[38;5;241m=\u001B[39munbuffered)\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_affected_rows\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:861\u001B[0m, in \u001B[0;36mConnection._execute_command\u001B[1;34m(self, command, sql)\u001B[0m\n\u001B[0;32m    859\u001B[0m prelude \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<iB\u001B[39m\u001B[38;5;124m\"\u001B[39m, packet_size, command)\n\u001B[0;32m    860\u001B[0m packet \u001B[38;5;241m=\u001B[39m prelude \u001B[38;5;241m+\u001B[39m sql[: packet_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m--> 861\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_write_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpacket\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DEBUG:\n\u001B[0;32m    863\u001B[0m     dump_packet(packet)\n",
      "File \u001B[1;32m~\\PycharmProjects\\gen_ai\\venv\\Lib\\site-packages\\pymysql\\connections.py:806\u001B[0m, in \u001B[0;36mConnection._write_bytes\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_force_close()\n\u001B[1;32m--> 806\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\u001B[38;5;241m.\u001B[39mOperationalError(\n\u001B[0;32m    807\u001B[0m         CR\u001B[38;5;241m.\u001B[39mCR_SERVER_GONE_ERROR, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMySQL server has gone away (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    808\u001B[0m     )\n",
      "\u001B[1;31mOperationalError\u001B[0m: (pymysql.err.OperationalError) (2006, \"MySQL server has gone away (ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\")\n[SQL: SELECT SUM(visits) AS total_visits\nFROM traffic_metrics\nWHERE Brand = 'Google'\n  AND model = 'Google Pixel 7 Pro'\n  AND date_of_metrics BETWEEN '2023-11-01' AND '2023-11-30';]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "agent.run(\"what is the traffic of google pixel 7 in November 2023?\")\n",
    "# agent.run(\"what were the sales for Pixel 7 Pro in 2023\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T20:39:47.679528Z",
     "start_time": "2023-12-26T20:39:42.497683300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage for the session: \n",
      "Tokens: 4436\n",
      "Cost: 0.00044360000000000005\n"
     ]
    }
   ],
   "source": [
    "agent.get_session_usage()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T10:23:06.092361400Z",
     "start_time": "2023-12-26T10:23:06.090341600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dictionary Output Methods"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T03:32:35.562236900Z",
     "start_time": "2023-12-26T03:32:29.856289400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated SQL Query: \n",
      "SELECT \n",
      "    SUM(CASE WHEN Brand = 'Google' THEN visits ELSE 0 END) - SUM(CASE WHEN Brand = 'Samsung' THEN visits ELSE 0 END) AS delta_total_visits\n",
      "FROM \n",
      "    traffic_metrics\n",
      "WHERE \n",
      "    partner = 'T-Mobile'\n",
      "    AND date_of_metrics BETWEEN '2023-11-01' AND '2023-11-07'\n",
      "    AND Brand IN ('Google', 'Samsung');\n",
      "\n",
      "Time taken for obtaining results: 5.698735299985856s\n"
     ]
    },
    {
     "data": {
      "text/plain": "'[{\"delta_total_visits\":-520124.3}]'"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "\n",
    "def get_table_schema_mysql(table_name, database_url):\n",
    "    engine = create_engine(database_url)\n",
    "    metadata = MetaData()\n",
    "\n",
    "    table = Table(table_name, metadata, autoload_with=engine)\n",
    "\n",
    "    if table.columns:\n",
    "        cols = [column.name for column in table.columns]\n",
    "        return cols\n",
    "    else:\n",
    "        print(f\"Table '{table_name}' not found.\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "instructions = {\n",
    "    'traffic_metrics': {\n",
    "        'date_of_metrics': f\"(in ISO format, for any time period, mention a range of dates in ISO format if date is mentioned otherwise Null. If you need to know the current date in order to determine the range of dates, current date is {date.today()}),\",\n",
    "        'partner_region': \"(Regions like EMEA, APAC, etc.),\",\n",
    "        'partner_country': \"(in locale code format only, example - US, JP, AU, UK),\",\n",
    "        'partner': \"(example - AT&T, KDDI, Online Docomo, Amazon, Flipkart, Saturn DE. These are vendors. Set it to Null when no partner is mentioned or detected partner is Apple, Google, etc),\",\n",
    "        'Brand': \"(Example - Apple, Google, Samsung, Oppo, Xiaomi, Android etc.), \",\n",
    "        'visits': \",\",\n",
    "        'model': \"(actual full official model names, example - 'Google Pixel 7 Pro', 'Apple iPhone 14', 'Samsung S21 Ultra'. If multiple Models exist, add a list a models),\"\n",
    "    },\n",
    "    \"sales_data\": {\n",
    "        'Week': \"(in integers(example 41),\",\n",
    "        'Year': \"(only Year in YYYY form)\",\n",
    "        'Partner': \"(example - AT&T, KDDI, Online Docomo. These are vendors. Partners cannot be Apple or Google.),\",\n",
    "        'Region Type': \",\",\n",
    "        'Region Breakdown': \",\",\n",
    "        'Product Model': \"(actual full official model names, example - 'Google Pixel 7 Pro', 'Apple iPhone 14', 'Samsung S21 Ultra'),\",\n",
    "        'Current Week Sales': \",\",\n",
    "        'Quarterly Target': \",\",\n",
    "        'QTD Sales': \",\",\n",
    "        'Current RR': \",\",\n",
    "        'Amended RR': \",\",\n",
    "        'Quarterly %': \",\"\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dictionary_output(prompt, llm):\n",
    "    table = classify_intent(text=prompt)\n",
    "    # table = \"sales_data\"\n",
    "    schema = get_table_schema_mysql(table, db_url)\n",
    "    print(f\"\\nUser Prompt: {prompt}\\nIdentified Table: {table}\")\n",
    "\n",
    "    prompt = f\"Extract {' '.join([str(header + instructions[table][header]) for header in schema])} from the following prompt: {prompt}. Also extract the of the user 'intent' behind the prompt(example - Total, Average, Highest sales', Lowest, Minimum , Maximum, SoT, WoW, delta(difference) etc. DESCRIBE THE INTENT VERBOSELY and provide context). Also find the TYPE OF OUTPUT expected (Example - Single Value or List of values or a DataFrame). Return the output in JSON format and if any data is not mentioned, leave the parameter empty.\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    calculate_and_update_cost(prompt, response)\n",
    "\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from langchain.llms import VertexAI\n",
    "# llm = VertexAI(model='text-bison', verbose=False)\n",
    "#\n",
    "# prompt1 = \"which country had the lowest visits for Google and Samsung between June to September 2023?\"\n",
    "# prompt2 = \"what we the quarterly sales of Google Pixel 6 in the November 2023?\"\n",
    "# prompt3 = \"Which Model had the higher traffic, Apple iphone 15 or Google Pixel 8 in United States for EMEA region by partner EE in Novemeber 2023?\"\n",
    "#\n",
    "# print(dictionary_output(prompt1, llm))\n",
    "# print(dictionary_output(prompt2, llm))\n",
    "# print(dictionary_output(prompt3, llm))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "llm = VertexAI(model='text-bison', verbose=True)\n",
    "\n",
    "prompt = \"Which Model had the higher traffic, Apple iPhone 15 or Google Pixel 8 in the United States for EMEA region by partner EE in November 2023, considering both online and offline visits?\"\n",
    "\n",
    "result = dictionary_output(prompt, llm)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sql_llm = VertexAI(model='code-bison', verbose=False)\n",
    "#\n",
    "# prompt = f\"I need you to generate an sql query for the table 'table_metrics' with the following columns except intent. Intent is the directions you are supposed to follow. {result}. return only the sql query.\"\n",
    "#\n",
    "# response = sql_llm.invoke(prompt)\n",
    "# calculate_and_update_cost(prompt, response)\n",
    "#\n",
    "# print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
